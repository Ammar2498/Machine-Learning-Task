# -*- coding: utf-8 -*-
"""Diabetes dataset .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ujptKt-xIRP7DekkLcaZjWGAlQ-TBr9D
"""

!pip install pandas

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import sklearn
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
plt.rcParams["figure.figsize"] = [10,5]

"""### **TRAINING DATA PRE-PROCESSING**
The first step in the machine learning pipeline is to clean and transform the training data into a useable format for analysis and modeling.   

As such, data pre-processing addresses:
- Assumptions about data shape
- Missing values
- Categorical variables
"""

full_data = pd.read_csv('/content/diabetes.csv')

print('train data:',full_data.shape)

# View first few rows
full_data.head(5)

# Data Info
full_data.info()

"""Missing Data
From the entry totals above, there appears to be missing data. A heatmap will help better visualize what features as missing the most information.
"""

# Heatmap
sns.heatmap(full_data.isnull(),yticklabels = False, cbar = False,cmap = 'tab20c_r')
plt.title('Missing Data: Training Set')
plt.show()

# Remove rows with missing data
full_data.dropna(inplace = True)

# number summary
full_data.describe()

"""## **OBJECTIVE 2: MACHINE LEARNING**
Next, I will feed these features into various classification algorithms to determine the best performance using a simple framework: **Split, Fit, Predict, Score It.**
"""

# Split data to be used in the models
# Create matrix of features
# X is input
x = full_data.drop('Outcome', axis = 1) # grabs everything else but 'Outcome'

# Create target variable
# Y is output
y = full_data['Outcome'] # y is the column we're trying to predict

# Use x and y variables to split the training data into train and test set
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify=y, random_state = 2)

print(x)

print(y)

x.shape

y.shape

"""LOGISTIC REGRESSION
use for classification

"""

# Fit
# Import model
from sklearn.linear_model import LogisticRegression

# Create instance of model
lreg = LogisticRegression()

# Pass training data into model
lreg.fit(x_train, y_train)

# Predict
y_pred_lreg = lreg.predict(x_test)
print(y_pred_lreg)

"""###Check the accuracy of the model"""

# Score It (to check accuracy)
from sklearn.metrics import classification_report, accuracy_score

print('Classification Model')
# Accuracy
print('--'*30)
logreg_accuracy = round(accuracy_score(y_test, y_pred_lreg) * 100,2)
print('Accuracy', logreg_accuracy,'%')